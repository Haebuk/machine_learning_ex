{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apr_Kaggle_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO46fDUScZkEOIr3xDuOY02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/machine_learning_ex/blob/master/Apr_Kaggle_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWNQV240FTA5"
      },
      "source": [
        "# 2021 Apr Modeling\n",
        "- [\n",
        "N3. [TPS April 21] LightAutoML starter](https://www.kaggle.com/alexryzhkov/n3-tps-april-21-lightautoml-starter)\n",
        "- [\n",
        "TPS Apr 2021 pseudo labeling/voting ensemble](https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble/notebook?select=pseudo_label.csv )\n",
        "- [Pseudolabelling - Tips and tricks](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/231738)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG3fMCQUJDO5"
      },
      "source": [
        "## Colab Softwrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ovzk0GEIqKe"
      },
      "source": [
        "# colab softwrap\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnLB6u12FeN-"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oGhOdt0OFuxZ",
        "outputId": "8a4ed740-0c60-496c-adbd-62cb2dc0fe00"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression as lr\n",
        "!pip install -q lightgbm==3.2.1\n",
        "import lightgbm as lgb\n",
        "!pip install -q catboost\n",
        "import catboost as ctb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "import graphviz\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 67.3MB 70kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmMjfKbfGN0e",
        "outputId": "9d177ec6-87e0-4559-d8d6-3f0356604d93"
      },
      "source": [
        "TARGET = 'Survived'\n",
        "\n",
        "N_THREADS = 4\n",
        "N_FOLDS = 10\n",
        "TEST_SIZE = 0.2\n",
        "TIMEOUT = 3 * 3600\n",
        "N_ESTIMATORS = 1000\n",
        "N_SPLITS = 10\n",
        "SEED = 2021\n",
        "EARLY_STOPPING_ROUNDS = 100 \n",
        "VERBOSE = 100"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0VyEnSRGGx_E",
        "outputId": "9ef0631a-b1dc-4f71-e5cd-d9a0c9b5b1c4"
      },
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "torch.set_num_threads(N_THREADS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWxKGbd9HKpR"
      },
      "source": [
        "## Git Clone & Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuYQFujBG7AF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "2d8e7d62-d1c7-4410-a0c0-28e403f05031"
      },
      "source": [
        "!git clone https://github.com/Haebuk/kuggle.git\n",
        "PATH = '/content/kuggle/9,10주차/input/'\n",
        "train_df = pd.read_csv(PATH+'train.csv')\n",
        "test_df = pd.read_csv(PATH+'test.csv')\n",
        "submission_df = pd.read_csv(PATH+'sample_submission.csv')\n",
        "\n",
        "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kuggle'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 59 (delta 12), reused 44 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYvlQw_ZHn_Z"
      },
      "source": [
        "## Filling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sWMTxsxvMfVD",
        "outputId": "53af49a7-4999-40d5-e229-bf2839c3cee3"
      },
      "source": [
        "all_df.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>199995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Cash, Cheryle</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7686</td>\n",
              "      <td>10.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>199996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Brown, Howard</td>\n",
              "      <td>male</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13004</td>\n",
              "      <td>68.31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>199997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Lightfoot, Cameron</td>\n",
              "      <td>male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4383317</td>\n",
              "      <td>10.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>199998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Jacobsen, Margaret</td>\n",
              "      <td>female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>PC 26988</td>\n",
              "      <td>29.68</td>\n",
              "      <td>B20828</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>199999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Fishback, Joanna</td>\n",
              "      <td>female</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>PC 41824</td>\n",
              "      <td>195.41</td>\n",
              "      <td>E13345</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PassengerId  Survived  Pclass  ...    Fare   Cabin  Embarked\n",
              "199995       199995       NaN       3  ...   10.12     NaN         Q\n",
              "199996       199996       NaN       1  ...   68.31     NaN         S\n",
              "199997       199997       NaN       3  ...   10.87     NaN         S\n",
              "199998       199998       NaN       1  ...   29.68  B20828         C\n",
              "199999       199999       NaN       1  ...  195.41  E13345         C\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "6o8MDiEsKfSX",
        "outputId": "07847cff-5210-4913-f257-e58788a3f423"
      },
      "source": [
        "for col in all_df.columns:\n",
        "    print(col, all_df[col].isnull().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "PassengerId 0\n",
            "Survived 100000\n",
            "Pclass 0\n",
            "Name 0\n",
            "Sex 0\n",
            "Age 6779\n",
            "SibSp 0\n",
            "Parch 0\n",
            "Ticket 9804\n",
            "Fare 267\n",
            "Cabin 138697\n",
            "Embarked 527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GKNoJbNuH4kU",
        "outputId": "0bf2d382-b212-4621-8d98-68835bc92c9a"
      },
      "source": [
        "def fill_nan_values(data):\n",
        "    # 연령 결측값 -> 평균으로 대체\n",
        "    data['Age'] = data['Age'].fillna(data['Age'].mean())\n",
        "    # 선실 결측값 -> X로 대체 및 나머지는 첫글자로 대체\n",
        "    data['Cabin'] = data['Cabin'].fillna('X').map(lambda x: x[0].strip())\n",
        "\n",
        "    # 티켓 결측값 -> X로 대체 및 나머지는 첫 어절로 대체\n",
        "    data['Ticket'] = data['Ticket'].fillna('X').\\\n",
        "    map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
        "\n",
        "    # 요금 결측값 -> Pclass의 중위수로 대체 후 로그변환(정규화)\n",
        "    fare_map = data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
        "    data['Fare'] = data['Fare'].fillna(data['Pclass'].map(fare_map['Fare']))\n",
        "    data['Fare'] = np.log1p(data['Fare'])\n",
        "\n",
        "    # 탑승항구 결측값 -> X로 대체\n",
        "    data['Embarked'] = data['Embarked'].fillna('X')\n",
        "\n",
        "    # 성을 제외한 이름만 추출\n",
        "    data['Name'] = data['Name'].map(lambda x: x.split(',')[0])\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQjcbl0S_zVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "843637c6-4f8b-4a41-972b-0e12a5c034df"
      },
      "source": [
        "all_df = fill_nan_values(all_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cO8x1GCNCfk"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tzQyUa0VHwbG",
        "outputId": "144f7556-c303-4588-a03a-c42187ac8089"
      },
      "source": [
        "label_cols = ['Name', 'Ticket', 'Sex']\n",
        "onehot_cols = ['Cabin', 'Embarked']\n",
        "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "COtcNVoJNhuD",
        "outputId": "9b90b7ae-de19-4731-c0a1-d6220ab2532a"
      },
      "source": [
        "def label_encoder(c):\n",
        "    le = LabelEncoder()\n",
        "    return le.fit_transform(c)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "onehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\n",
        "label_encoded_df = all_df[label_cols].apply(label_encoder)\n",
        "numerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), \n",
        "                            columns=numerical_cols)\n",
        "target_df = all_df[TARGET]\n",
        "\n",
        "all_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df],\\\n",
        "                   axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a7V7ocBtduDc",
        "outputId": "26fb4780-8aa5-462e-f51d-80c334e30694"
      },
      "source": [
        "# 피쳐 엔지니어링 후 다시 train/ test 분리\n",
        "train_df2 = all_df[:train_df.shape[0]]\n",
        "test_df2 = all_df[train_df.shape[0]:]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKbDMU4SFEKG"
      },
      "source": [
        "## Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jNn83Q_VFHAF",
        "outputId": "4e2117b9-f8ba-40fb-d749-937c9c8fbfce"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "X_test = test_df2.drop(TARGET, axis=1)\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = lr(max_iter=300, verbose=VERBOSE)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    lr_val = model.predict(X_valid)\n",
        "    lr_val = [1 if v >= 0.5 else 0 for v in lr_val]\n",
        "    lr_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, lr_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
            "===== ACCURACY SCORE 0.761900 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n",
            "===== ACCURACY SCORE 0.773500 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
            "===== ACCURACY SCORE 0.769900 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
            "===== ACCURACY SCORE 0.768700 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
            "===== ACCURACY SCORE 0.758300 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
            "===== ACCURACY SCORE 0.685500 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
            "===== ACCURACY SCORE 0.688800 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
            "===== ACCURACY SCORE 0.772600 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s finished\n",
            "===== ACCURACY SCORE 0.767800 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
            "===== ACCURACY SCORE 0.765200 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Iyn3RIif2uc5",
        "outputId": "0454e5e0-a240-40fd-b43a-62c7ec570d5a"
      },
      "source": [
        "submission_df_lr = pd.read_csv(PATH+'sample_submission.csv')\n",
        "submission_df_lr['Survived'] = lr_preds\n",
        "submission_df_lr.to_csv('lr_model.csv', index=False) # 0.78550 score"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee42ZGlRPOhA"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ipvauXRYPSRP",
        "outputId": "63dd39e5-408e-4498-f71e-1880d01a3128"
      },
      "source": [
        "params_lgb = {\n",
        "    'metric': 'binary_logloss',\n",
        "    'n_estimators': N_ESTIMATORS,\n",
        "    'objective': 'binary',\n",
        "    'random_state': SEED,\n",
        "    'learning_rate': 0.01,\n",
        "    'min_child_samples': 150,\n",
        "    'reg_alpha': 3e-5,\n",
        "    'reg_lambda': 9e-2,\n",
        "    'num_leaves': 20,\n",
        "    'max_depth': 16,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'subsample_freq': 2,\n",
        "    'max_bin': 240,\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EYvD38FQPYkl",
        "outputId": "420639b2-3eb9-42fe-f5e7-97ba35a270e9"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "X_test = test_df2.drop(TARGET, axis=1)\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    pre_model = lgb.LGBMRegressor(**params_lgb)\n",
        "    pre_model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "        early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n",
        "        verbose = VERBOSE\n",
        "    )\n",
        "\n",
        "    params_lgb2 = params_lgb.copy()\n",
        "    params_lgb2['learning_rate'] = params_lgb['learning_rate'] * 0.1\n",
        "    model = lgb.LGBMRegressor(**params_lgb2)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
        "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "        verbose=VERBOSE,\n",
        "        init_model=pre_model\n",
        "    )\n",
        "\n",
        "    # feature importance\n",
        "    fi_tmp = pd.DataFrame()\n",
        "    fi_tmp['feature'] = model.feature_name_\n",
        "    fi_tmp['importance'] = model.feature_importances_\n",
        "    fi_tmp['fold'] = fold\n",
        "    fi_tmp['seed'] = SEED\n",
        "    feature_importances = feature_importances.append(fi_tmp)\n",
        "    \n",
        "    lgb_val = model.predict(X_valid)\n",
        "    lgb_val = [1 if v >= 0.5 else 0 for v in lgb_val]\n",
        "    lgb_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, lgb_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52195\tvalid_1's binary_logloss: 0.523998\n",
            "[200]\ttraining's binary_logloss: 0.484826\tvalid_1's binary_logloss: 0.488637\n",
            "[300]\ttraining's binary_logloss: 0.473859\tvalid_1's binary_logloss: 0.479154\n",
            "[400]\ttraining's binary_logloss: 0.469461\tvalid_1's binary_logloss: 0.475771\n",
            "[500]\ttraining's binary_logloss: 0.467025\tvalid_1's binary_logloss: 0.474104\n",
            "[600]\ttraining's binary_logloss: 0.465386\tvalid_1's binary_logloss: 0.473314\n",
            "[700]\ttraining's binary_logloss: 0.464096\tvalid_1's binary_logloss: 0.472792\n",
            "[800]\ttraining's binary_logloss: 0.463023\tvalid_1's binary_logloss: 0.472523\n",
            "[900]\ttraining's binary_logloss: 0.462084\tvalid_1's binary_logloss: 0.47237\n",
            "[1000]\ttraining's binary_logloss: 0.461183\tvalid_1's binary_logloss: 0.472227\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461183\tvalid_1's binary_logloss: 0.472227\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461094\tvalid_1's binary_logloss: 0.472222\n",
            "[1200]\ttraining's binary_logloss: 0.461009\tvalid_1's binary_logloss: 0.472211\n",
            "[1300]\ttraining's binary_logloss: 0.460925\tvalid_1's binary_logloss: 0.472204\n",
            "[1400]\ttraining's binary_logloss: 0.460844\tvalid_1's binary_logloss: 0.472201\n",
            "Early stopping, best iteration is:\n",
            "[1390]\ttraining's binary_logloss: 0.460852\tvalid_1's binary_logloss: 0.4722\n",
            "===== ACCURACY SCORE 0.779000 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522704\tvalid_1's binary_logloss: 0.51918\n",
            "[200]\ttraining's binary_logloss: 0.485975\tvalid_1's binary_logloss: 0.481349\n",
            "[300]\ttraining's binary_logloss: 0.475115\tvalid_1's binary_logloss: 0.470225\n",
            "[400]\ttraining's binary_logloss: 0.47075\tvalid_1's binary_logloss: 0.466134\n",
            "[500]\ttraining's binary_logloss: 0.468332\tvalid_1's binary_logloss: 0.464304\n",
            "[600]\ttraining's binary_logloss: 0.466676\tvalid_1's binary_logloss: 0.4633\n",
            "[700]\ttraining's binary_logloss: 0.465409\tvalid_1's binary_logloss: 0.462813\n",
            "[800]\ttraining's binary_logloss: 0.464352\tvalid_1's binary_logloss: 0.46249\n",
            "[900]\ttraining's binary_logloss: 0.463402\tvalid_1's binary_logloss: 0.462298\n",
            "[1000]\ttraining's binary_logloss: 0.462511\tvalid_1's binary_logloss: 0.462152\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462511\tvalid_1's binary_logloss: 0.462152\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.462424\tvalid_1's binary_logloss: 0.462135\n",
            "[1200]\ttraining's binary_logloss: 0.462342\tvalid_1's binary_logloss: 0.462124\n",
            "[1300]\ttraining's binary_logloss: 0.462258\tvalid_1's binary_logloss: 0.462108\n",
            "[1400]\ttraining's binary_logloss: 0.462174\tvalid_1's binary_logloss: 0.462093\n",
            "[1500]\ttraining's binary_logloss: 0.462089\tvalid_1's binary_logloss: 0.462085\n",
            "[1600]\ttraining's binary_logloss: 0.462005\tvalid_1's binary_logloss: 0.462073\n",
            "[1700]\ttraining's binary_logloss: 0.461922\tvalid_1's binary_logloss: 0.462058\n",
            "[1800]\ttraining's binary_logloss: 0.461837\tvalid_1's binary_logloss: 0.462044\n",
            "[1900]\ttraining's binary_logloss: 0.461756\tvalid_1's binary_logloss: 0.462034\n",
            "[2000]\ttraining's binary_logloss: 0.461675\tvalid_1's binary_logloss: 0.462022\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461675\tvalid_1's binary_logloss: 0.462022\n",
            "===== ACCURACY SCORE 0.788600 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522037\tvalid_1's binary_logloss: 0.52336\n",
            "[200]\ttraining's binary_logloss: 0.485134\tvalid_1's binary_logloss: 0.487293\n",
            "[300]\ttraining's binary_logloss: 0.474239\tvalid_1's binary_logloss: 0.476999\n",
            "[400]\ttraining's binary_logloss: 0.469852\tvalid_1's binary_logloss: 0.473221\n",
            "[500]\ttraining's binary_logloss: 0.467434\tvalid_1's binary_logloss: 0.471488\n",
            "[600]\ttraining's binary_logloss: 0.465755\tvalid_1's binary_logloss: 0.470694\n",
            "[700]\ttraining's binary_logloss: 0.46447\tvalid_1's binary_logloss: 0.470194\n",
            "[800]\ttraining's binary_logloss: 0.463379\tvalid_1's binary_logloss: 0.469959\n",
            "[900]\ttraining's binary_logloss: 0.46241\tvalid_1's binary_logloss: 0.469866\n",
            "Early stopping, best iteration is:\n",
            "[868]\ttraining's binary_logloss: 0.46272\tvalid_1's binary_logloss: 0.46985\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[900]\ttraining's binary_logloss: 0.46269\tvalid_1's binary_logloss: 0.469848\n",
            "[1000]\ttraining's binary_logloss: 0.462597\tvalid_1's binary_logloss: 0.469837\n",
            "[1100]\ttraining's binary_logloss: 0.462507\tvalid_1's binary_logloss: 0.469835\n",
            "[1200]\ttraining's binary_logloss: 0.462418\tvalid_1's binary_logloss: 0.469825\n",
            "[1300]\ttraining's binary_logloss: 0.462328\tvalid_1's binary_logloss: 0.469814\n",
            "[1400]\ttraining's binary_logloss: 0.462236\tvalid_1's binary_logloss: 0.469806\n",
            "[1500]\ttraining's binary_logloss: 0.462147\tvalid_1's binary_logloss: 0.469804\n",
            "[1600]\ttraining's binary_logloss: 0.462055\tvalid_1's binary_logloss: 0.469788\n",
            "[1700]\ttraining's binary_logloss: 0.461964\tvalid_1's binary_logloss: 0.469778\n",
            "[1800]\ttraining's binary_logloss: 0.461877\tvalid_1's binary_logloss: 0.469778\n",
            "Early stopping, best iteration is:\n",
            "[1722]\ttraining's binary_logloss: 0.461944\tvalid_1's binary_logloss: 0.469776\n",
            "===== ACCURACY SCORE 0.783600 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.521861\tvalid_1's binary_logloss: 0.525059\n",
            "[200]\ttraining's binary_logloss: 0.484797\tvalid_1's binary_logloss: 0.489376\n",
            "[300]\ttraining's binary_logloss: 0.473825\tvalid_1's binary_logloss: 0.479643\n",
            "[400]\ttraining's binary_logloss: 0.469374\tvalid_1's binary_logloss: 0.476104\n",
            "[500]\ttraining's binary_logloss: 0.466966\tvalid_1's binary_logloss: 0.474579\n",
            "[600]\ttraining's binary_logloss: 0.465295\tvalid_1's binary_logloss: 0.473908\n",
            "[700]\ttraining's binary_logloss: 0.464016\tvalid_1's binary_logloss: 0.473556\n",
            "[800]\ttraining's binary_logloss: 0.462937\tvalid_1's binary_logloss: 0.473298\n",
            "[900]\ttraining's binary_logloss: 0.462013\tvalid_1's binary_logloss: 0.473216\n",
            "[1000]\ttraining's binary_logloss: 0.461104\tvalid_1's binary_logloss: 0.473122\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461104\tvalid_1's binary_logloss: 0.473122\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461017\tvalid_1's binary_logloss: 0.473129\n",
            "Early stopping, best iteration is:\n",
            "[1021]\ttraining's binary_logloss: 0.461086\tvalid_1's binary_logloss: 0.473122\n",
            "===== ACCURACY SCORE 0.782800 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52201\tvalid_1's binary_logloss: 0.524383\n",
            "[200]\ttraining's binary_logloss: 0.485011\tvalid_1's binary_logloss: 0.48873\n",
            "[300]\ttraining's binary_logloss: 0.474128\tvalid_1's binary_logloss: 0.47843\n",
            "[400]\ttraining's binary_logloss: 0.469787\tvalid_1's binary_logloss: 0.474651\n",
            "[500]\ttraining's binary_logloss: 0.467342\tvalid_1's binary_logloss: 0.472865\n",
            "[600]\ttraining's binary_logloss: 0.465677\tvalid_1's binary_logloss: 0.471931\n",
            "[700]\ttraining's binary_logloss: 0.46442\tvalid_1's binary_logloss: 0.471467\n",
            "[800]\ttraining's binary_logloss: 0.463335\tvalid_1's binary_logloss: 0.471189\n",
            "[900]\ttraining's binary_logloss: 0.462388\tvalid_1's binary_logloss: 0.471068\n",
            "[1000]\ttraining's binary_logloss: 0.461492\tvalid_1's binary_logloss: 0.471036\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461492\tvalid_1's binary_logloss: 0.471036\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461405\tvalid_1's binary_logloss: 0.471027\n",
            "[1200]\ttraining's binary_logloss: 0.461318\tvalid_1's binary_logloss: 0.471022\n",
            "[1300]\ttraining's binary_logloss: 0.461231\tvalid_1's binary_logloss: 0.471011\n",
            "[1400]\ttraining's binary_logloss: 0.461146\tvalid_1's binary_logloss: 0.471005\n",
            "[1500]\ttraining's binary_logloss: 0.461061\tvalid_1's binary_logloss: 0.471002\n",
            "[1600]\ttraining's binary_logloss: 0.46098\tvalid_1's binary_logloss: 0.470992\n",
            "[1700]\ttraining's binary_logloss: 0.460895\tvalid_1's binary_logloss: 0.470987\n",
            "[1800]\ttraining's binary_logloss: 0.46081\tvalid_1's binary_logloss: 0.470985\n",
            "[1900]\ttraining's binary_logloss: 0.460732\tvalid_1's binary_logloss: 0.47098\n",
            "[2000]\ttraining's binary_logloss: 0.46065\tvalid_1's binary_logloss: 0.470982\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.46065\tvalid_1's binary_logloss: 0.470982\n",
            "===== ACCURACY SCORE 0.780400 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522394\tvalid_1's binary_logloss: 0.522067\n",
            "[200]\ttraining's binary_logloss: 0.485488\tvalid_1's binary_logloss: 0.485128\n",
            "[300]\ttraining's binary_logloss: 0.474652\tvalid_1's binary_logloss: 0.47446\n",
            "[400]\ttraining's binary_logloss: 0.470278\tvalid_1's binary_logloss: 0.470521\n",
            "[500]\ttraining's binary_logloss: 0.467829\tvalid_1's binary_logloss: 0.468664\n",
            "[600]\ttraining's binary_logloss: 0.466182\tvalid_1's binary_logloss: 0.467694\n",
            "[700]\ttraining's binary_logloss: 0.464921\tvalid_1's binary_logloss: 0.467171\n",
            "[800]\ttraining's binary_logloss: 0.463883\tvalid_1's binary_logloss: 0.466879\n",
            "[900]\ttraining's binary_logloss: 0.462916\tvalid_1's binary_logloss: 0.466704\n",
            "[1000]\ttraining's binary_logloss: 0.462041\tvalid_1's binary_logloss: 0.466565\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462041\tvalid_1's binary_logloss: 0.466565\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461953\tvalid_1's binary_logloss: 0.466547\n",
            "[1200]\ttraining's binary_logloss: 0.461867\tvalid_1's binary_logloss: 0.466533\n",
            "[1300]\ttraining's binary_logloss: 0.461782\tvalid_1's binary_logloss: 0.466529\n",
            "[1400]\ttraining's binary_logloss: 0.461697\tvalid_1's binary_logloss: 0.466509\n",
            "[1500]\ttraining's binary_logloss: 0.461613\tvalid_1's binary_logloss: 0.466499\n",
            "[1600]\ttraining's binary_logloss: 0.461526\tvalid_1's binary_logloss: 0.466485\n",
            "[1700]\ttraining's binary_logloss: 0.461442\tvalid_1's binary_logloss: 0.466475\n",
            "[1800]\ttraining's binary_logloss: 0.46136\tvalid_1's binary_logloss: 0.466469\n",
            "[1900]\ttraining's binary_logloss: 0.461277\tvalid_1's binary_logloss: 0.46646\n",
            "[2000]\ttraining's binary_logloss: 0.461195\tvalid_1's binary_logloss: 0.466455\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461195\tvalid_1's binary_logloss: 0.466455\n",
            "===== ACCURACY SCORE 0.785000 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52284\tvalid_1's binary_logloss: 0.518276\n",
            "[200]\ttraining's binary_logloss: 0.486072\tvalid_1's binary_logloss: 0.479885\n",
            "[300]\ttraining's binary_logloss: 0.475282\tvalid_1's binary_logloss: 0.468872\n",
            "[400]\ttraining's binary_logloss: 0.47092\tvalid_1's binary_logloss: 0.46473\n",
            "[500]\ttraining's binary_logloss: 0.468545\tvalid_1's binary_logloss: 0.462797\n",
            "[600]\ttraining's binary_logloss: 0.466879\tvalid_1's binary_logloss: 0.461706\n",
            "[700]\ttraining's binary_logloss: 0.465663\tvalid_1's binary_logloss: 0.461122\n",
            "[800]\ttraining's binary_logloss: 0.464624\tvalid_1's binary_logloss: 0.460814\n",
            "[900]\ttraining's binary_logloss: 0.463697\tvalid_1's binary_logloss: 0.460658\n",
            "[1000]\ttraining's binary_logloss: 0.462815\tvalid_1's binary_logloss: 0.460485\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462815\tvalid_1's binary_logloss: 0.460485\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.462729\tvalid_1's binary_logloss: 0.460469\n",
            "[1200]\ttraining's binary_logloss: 0.462641\tvalid_1's binary_logloss: 0.460455\n",
            "[1300]\ttraining's binary_logloss: 0.462555\tvalid_1's binary_logloss: 0.460446\n",
            "[1400]\ttraining's binary_logloss: 0.462475\tvalid_1's binary_logloss: 0.460429\n",
            "[1500]\ttraining's binary_logloss: 0.462392\tvalid_1's binary_logloss: 0.460407\n",
            "[1600]\ttraining's binary_logloss: 0.46231\tvalid_1's binary_logloss: 0.460397\n",
            "[1700]\ttraining's binary_logloss: 0.462228\tvalid_1's binary_logloss: 0.460383\n",
            "[1800]\ttraining's binary_logloss: 0.462146\tvalid_1's binary_logloss: 0.460371\n",
            "[1900]\ttraining's binary_logloss: 0.462069\tvalid_1's binary_logloss: 0.46036\n",
            "[2000]\ttraining's binary_logloss: 0.461988\tvalid_1's binary_logloss: 0.460348\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461988\tvalid_1's binary_logloss: 0.460348\n",
            "===== ACCURACY SCORE 0.785900 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522559\tvalid_1's binary_logloss: 0.519849\n",
            "[200]\ttraining's binary_logloss: 0.485761\tvalid_1's binary_logloss: 0.482267\n",
            "[300]\ttraining's binary_logloss: 0.47484\tvalid_1's binary_logloss: 0.471547\n",
            "[400]\ttraining's binary_logloss: 0.470435\tvalid_1's binary_logloss: 0.467685\n",
            "[500]\ttraining's binary_logloss: 0.468023\tvalid_1's binary_logloss: 0.465999\n",
            "[600]\ttraining's binary_logloss: 0.466297\tvalid_1's binary_logloss: 0.465284\n",
            "[700]\ttraining's binary_logloss: 0.465021\tvalid_1's binary_logloss: 0.465012\n",
            "[800]\ttraining's binary_logloss: 0.463949\tvalid_1's binary_logloss: 0.464953\n",
            "Early stopping, best iteration is:\n",
            "[731]\ttraining's binary_logloss: 0.464674\tvalid_1's binary_logloss: 0.464943\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[800]\ttraining's binary_logloss: 0.464598\tvalid_1's binary_logloss: 0.464942\n",
            "Early stopping, best iteration is:\n",
            "[743]\ttraining's binary_logloss: 0.464661\tvalid_1's binary_logloss: 0.46494\n",
            "===== ACCURACY SCORE 0.788800 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.521548\tvalid_1's binary_logloss: 0.526133\n",
            "[200]\ttraining's binary_logloss: 0.484561\tvalid_1's binary_logloss: 0.491406\n",
            "[300]\ttraining's binary_logloss: 0.473623\tvalid_1's binary_logloss: 0.481902\n",
            "[400]\ttraining's binary_logloss: 0.469182\tvalid_1's binary_logloss: 0.478545\n",
            "[500]\ttraining's binary_logloss: 0.466746\tvalid_1's binary_logloss: 0.477057\n",
            "[600]\ttraining's binary_logloss: 0.46508\tvalid_1's binary_logloss: 0.47628\n",
            "[700]\ttraining's binary_logloss: 0.463803\tvalid_1's binary_logloss: 0.475882\n",
            "[800]\ttraining's binary_logloss: 0.462753\tvalid_1's binary_logloss: 0.475661\n",
            "[900]\ttraining's binary_logloss: 0.46183\tvalid_1's binary_logloss: 0.475518\n",
            "[1000]\ttraining's binary_logloss: 0.460941\tvalid_1's binary_logloss: 0.47539\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.460941\tvalid_1's binary_logloss: 0.47539\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.460853\tvalid_1's binary_logloss: 0.475376\n",
            "[1200]\ttraining's binary_logloss: 0.460767\tvalid_1's binary_logloss: 0.475366\n",
            "[1300]\ttraining's binary_logloss: 0.460682\tvalid_1's binary_logloss: 0.475361\n",
            "[1400]\ttraining's binary_logloss: 0.460595\tvalid_1's binary_logloss: 0.475355\n",
            "[1500]\ttraining's binary_logloss: 0.46051\tvalid_1's binary_logloss: 0.475339\n",
            "[1600]\ttraining's binary_logloss: 0.460426\tvalid_1's binary_logloss: 0.475333\n",
            "[1700]\ttraining's binary_logloss: 0.460339\tvalid_1's binary_logloss: 0.475328\n",
            "[1800]\ttraining's binary_logloss: 0.460256\tvalid_1's binary_logloss: 0.475324\n",
            "[1900]\ttraining's binary_logloss: 0.460176\tvalid_1's binary_logloss: 0.475321\n",
            "[2000]\ttraining's binary_logloss: 0.460095\tvalid_1's binary_logloss: 0.475308\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.460095\tvalid_1's binary_logloss: 0.475308\n",
            "===== ACCURACY SCORE 0.777400 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522051\tvalid_1's binary_logloss: 0.524528\n",
            "[200]\ttraining's binary_logloss: 0.485098\tvalid_1's binary_logloss: 0.488465\n",
            "[300]\ttraining's binary_logloss: 0.474082\tvalid_1's binary_logloss: 0.478293\n",
            "[400]\ttraining's binary_logloss: 0.469621\tvalid_1's binary_logloss: 0.474788\n",
            "[500]\ttraining's binary_logloss: 0.467216\tvalid_1's binary_logloss: 0.473346\n",
            "[600]\ttraining's binary_logloss: 0.465546\tvalid_1's binary_logloss: 0.472598\n",
            "[700]\ttraining's binary_logloss: 0.464263\tvalid_1's binary_logloss: 0.472206\n",
            "[800]\ttraining's binary_logloss: 0.463152\tvalid_1's binary_logloss: 0.472047\n",
            "[900]\ttraining's binary_logloss: 0.462188\tvalid_1's binary_logloss: 0.472021\n",
            "[1000]\ttraining's binary_logloss: 0.46129\tvalid_1's binary_logloss: 0.471981\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.46129\tvalid_1's binary_logloss: 0.471981\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461201\tvalid_1's binary_logloss: 0.471992\n",
            "Early stopping, best iteration is:\n",
            "[1002]\ttraining's binary_logloss: 0.461288\tvalid_1's binary_logloss: 0.471981\n",
            "===== ACCURACY SCORE 0.777600 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w-pt51lqvji"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "x7v8OE6HqvRB",
        "outputId": "36dde563-77a4-4bd8-dc1c-64e16a319aa3"
      },
      "source": [
        "order = list(feature_importances.groupby('feature').mean().\\\n",
        "             sort_values('importance', ascending=False).index)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importances, order=order)\n",
        "plt.title('{} importance'.format('LGBMRegressor'))\n",
        "plt.tight_layout()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEGugBkPrNyk"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4Pe28sfHrRwq",
        "outputId": "bbad86f2-050b-4f4f-a239-0f6316f9a8f8"
      },
      "source": [
        "params = {\n",
        "    'bootstrap_type': 'Poisson',\n",
        "    'loss_function': 'Logloss',\n",
        "    'eval_metric': 'Logloss',\n",
        "    'random_seed': SEED,\n",
        "    'task_type': 'GPU',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.01,\n",
        "    'n_estimators': N_ESTIMATORS,\n",
        "    'max_bin': 280,\n",
        "    'min_data_in_leaf': 64,\n",
        "    'l2_leaf_reg': 0.01,\n",
        "    'subsample': 0.8\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FB3NWFJ3rTGC",
        "outputId": "e6944dd2-66af-4c05-c4fd-249bf5fa7b5a"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = ctb.CatBoostClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        use_best_model = True,\n",
        "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "        verbose=VERBOSE,\n",
        "    )\n",
        "\n",
        "    # feature importance\n",
        "    fi_tmp = pd.DataFrame()\n",
        "    fi_tmp['feature'] = X_test.columns.to_list()\n",
        "    fi_tmp['importance'] = model.get_feature_importance()\n",
        "    fi_tmp['fold'] = fold\n",
        "    fi_tmp['seed'] = SEED\n",
        "    feature_importances = feature_importances.append(fi_tmp)\n",
        "    \n",
        "    ctb_val = model.predict(X_valid)\n",
        "    ctb_val = [1 if v >= 0.5 else 0 for v in ctb_val]\n",
        "    ctb_preds = model.predict(X_test)\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, ctb_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "0:\tlearn: 0.6880903\ttest: 0.6881691\tbest: 0.6881691 (0)\ttotal: 12.4ms\tremaining: 12.4s\n",
            "100:\tlearn: 0.4980883\ttest: 0.5026086\tbest: 0.5026086 (100)\ttotal: 1.12s\tremaining: 9.98s\n",
            "200:\tlearn: 0.4738352\ttest: 0.4815454\tbest: 0.4815454 (200)\ttotal: 2.21s\tremaining: 8.81s\n",
            "300:\tlearn: 0.4671796\ttest: 0.4774460\tbest: 0.4774460 (300)\ttotal: 3.31s\tremaining: 7.69s\n",
            "400:\tlearn: 0.4635169\ttest: 0.4758125\tbest: 0.4758125 (400)\ttotal: 4.42s\tremaining: 6.6s\n",
            "500:\tlearn: 0.4606931\ttest: 0.4749790\tbest: 0.4749790 (500)\ttotal: 5.53s\tremaining: 5.51s\n",
            "600:\tlearn: 0.4582370\ttest: 0.4745422\tbest: 0.4745422 (600)\ttotal: 6.62s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4560694\ttest: 0.4743346\tbest: 0.4743346 (700)\ttotal: 7.72s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4538918\ttest: 0.4742854\tbest: 0.4742854 (800)\ttotal: 8.81s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4517679\ttest: 0.4742644\tbest: 0.4742418 (851)\ttotal: 9.93s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4498496\ttest: 0.4742635\tbest: 0.4741753 (985)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4741753418\n",
            "bestIteration = 985\n",
            "Shrink model to first 986 iterations.\n",
            "===== ACCURACY SCORE 0.777500 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "0:\tlearn: 0.6881301\ttest: 0.6880576\tbest: 0.6880576 (0)\ttotal: 11.8ms\tremaining: 11.8s\n",
            "100:\tlearn: 0.4989181\ttest: 0.4959833\tbest: 0.4959833 (100)\ttotal: 1.08s\tremaining: 9.63s\n",
            "200:\tlearn: 0.4749071\ttest: 0.4723797\tbest: 0.4723797 (200)\ttotal: 2.18s\tremaining: 8.67s\n",
            "300:\tlearn: 0.4682804\ttest: 0.4674552\tbest: 0.4674552 (300)\ttotal: 3.29s\tremaining: 7.63s\n",
            "400:\tlearn: 0.4645074\ttest: 0.4656215\tbest: 0.4656215 (400)\ttotal: 4.39s\tremaining: 6.55s\n",
            "500:\tlearn: 0.4618833\ttest: 0.4649133\tbest: 0.4648973 (493)\ttotal: 5.47s\tremaining: 5.45s\n",
            "600:\tlearn: 0.4594836\ttest: 0.4644700\tbest: 0.4644700 (600)\ttotal: 6.61s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4571079\ttest: 0.4641784\tbest: 0.4641729 (698)\ttotal: 7.71s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4549848\ttest: 0.4638469\tbest: 0.4638469 (800)\ttotal: 8.81s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4529547\ttest: 0.4637246\tbest: 0.4637079 (891)\ttotal: 9.93s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4509703\ttest: 0.4635088\tbest: 0.4634876 (994)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4634875977\n",
            "bestIteration = 994\n",
            "Shrink model to first 995 iterations.\n",
            "===== ACCURACY SCORE 0.788700 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "0:\tlearn: 0.6881059\ttest: 0.6881238\tbest: 0.6881238 (0)\ttotal: 11.7ms\tremaining: 11.7s\n",
            "100:\tlearn: 0.4981557\ttest: 0.5012880\tbest: 0.5012880 (100)\ttotal: 1.1s\tremaining: 9.76s\n",
            "200:\tlearn: 0.4742765\ttest: 0.4797428\tbest: 0.4797428 (200)\ttotal: 2.21s\tremaining: 8.8s\n",
            "300:\tlearn: 0.4676985\ttest: 0.4750073\tbest: 0.4750073 (300)\ttotal: 3.32s\tremaining: 7.71s\n",
            "400:\tlearn: 0.4639450\ttest: 0.4734025\tbest: 0.4734025 (400)\ttotal: 4.42s\tremaining: 6.6s\n",
            "500:\tlearn: 0.4612056\ttest: 0.4725681\tbest: 0.4725667 (499)\ttotal: 5.52s\tremaining: 5.5s\n",
            "600:\tlearn: 0.4586924\ttest: 0.4721410\tbest: 0.4721410 (600)\ttotal: 6.62s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4564295\ttest: 0.4717236\tbest: 0.4717236 (700)\ttotal: 7.71s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4542557\ttest: 0.4714152\tbest: 0.4714136 (796)\ttotal: 8.79s\tremaining: 2.18s\n",
            "900:\tlearn: 0.4522211\ttest: 0.4711546\tbest: 0.4711288 (894)\ttotal: 9.9s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4502007\ttest: 0.4710301\tbest: 0.4710146 (985)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4710146484\n",
            "bestIteration = 985\n",
            "Shrink model to first 986 iterations.\n",
            "===== ACCURACY SCORE 0.782600 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "0:\tlearn: 0.6882077\ttest: 0.6883021\tbest: 0.6883021 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
            "100:\tlearn: 0.4979888\ttest: 0.5028313\tbest: 0.5028313 (100)\ttotal: 1.08s\tremaining: 9.62s\n",
            "200:\tlearn: 0.4735675\ttest: 0.4813335\tbest: 0.4813335 (200)\ttotal: 2.19s\tremaining: 8.71s\n",
            "300:\tlearn: 0.4670221\ttest: 0.4775033\tbest: 0.4775033 (300)\ttotal: 3.3s\tremaining: 7.66s\n",
            "400:\tlearn: 0.4633883\ttest: 0.4759787\tbest: 0.4759787 (400)\ttotal: 4.41s\tremaining: 6.58s\n",
            "500:\tlearn: 0.4606370\ttest: 0.4752685\tbest: 0.4752597 (498)\ttotal: 5.5s\tremaining: 5.48s\n",
            "600:\tlearn: 0.4582572\ttest: 0.4747245\tbest: 0.4747194 (598)\ttotal: 6.6s\tremaining: 4.38s\n",
            "700:\tlearn: 0.4559579\ttest: 0.4743777\tbest: 0.4743777 (700)\ttotal: 7.7s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4538545\ttest: 0.4742248\tbest: 0.4742248 (800)\ttotal: 8.8s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4518229\ttest: 0.4740613\tbest: 0.4740601 (898)\ttotal: 9.91s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4498475\ttest: 0.4740339\tbest: 0.4739489 (940)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4739489258\n",
            "bestIteration = 940\n",
            "Shrink model to first 941 iterations.\n",
            "===== ACCURACY SCORE 0.784300 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "0:\tlearn: 0.6880970\ttest: 0.6881526\tbest: 0.6881526 (0)\ttotal: 11.5ms\tremaining: 11.5s\n",
            "100:\tlearn: 0.4981148\ttest: 0.5016006\tbest: 0.5016006 (100)\ttotal: 1.09s\tremaining: 9.74s\n",
            "200:\tlearn: 0.4740902\ttest: 0.4799788\tbest: 0.4799788 (200)\ttotal: 2.19s\tremaining: 8.7s\n",
            "300:\tlearn: 0.4674480\ttest: 0.4757878\tbest: 0.4757878 (300)\ttotal: 3.31s\tremaining: 7.69s\n",
            "400:\tlearn: 0.4638453\ttest: 0.4742245\tbest: 0.4742224 (399)\ttotal: 4.41s\tremaining: 6.58s\n",
            "500:\tlearn: 0.4611643\ttest: 0.4734502\tbest: 0.4734502 (500)\ttotal: 5.5s\tremaining: 5.48s\n",
            "600:\tlearn: 0.4585928\ttest: 0.4728625\tbest: 0.4728625 (600)\ttotal: 6.61s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4563837\ttest: 0.4725625\tbest: 0.4725567 (684)\ttotal: 7.71s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4540691\ttest: 0.4722633\tbest: 0.4722593 (798)\ttotal: 8.82s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4521693\ttest: 0.4721735\tbest: 0.4721418 (837)\ttotal: 9.9s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4502089\ttest: 0.4721731\tbest: 0.4721337 (941)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4721337402\n",
            "bestIteration = 941\n",
            "Shrink model to first 942 iterations.\n",
            "===== ACCURACY SCORE 0.782400 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "0:\tlearn: 0.6881097\ttest: 0.6881271\tbest: 0.6881271 (0)\ttotal: 11.5ms\tremaining: 11.5s\n",
            "100:\tlearn: 0.4986190\ttest: 0.4994727\tbest: 0.4994727 (100)\ttotal: 1.1s\tremaining: 9.77s\n",
            "200:\tlearn: 0.4746137\ttest: 0.4769319\tbest: 0.4769319 (200)\ttotal: 2.22s\tremaining: 8.84s\n",
            "300:\tlearn: 0.4679631\ttest: 0.4723263\tbest: 0.4723263 (300)\ttotal: 3.33s\tremaining: 7.74s\n",
            "400:\tlearn: 0.4642275\ttest: 0.4702713\tbest: 0.4702713 (400)\ttotal: 4.43s\tremaining: 6.61s\n",
            "500:\tlearn: 0.4614574\ttest: 0.4692014\tbest: 0.4692014 (500)\ttotal: 5.54s\tremaining: 5.51s\n",
            "600:\tlearn: 0.4589809\ttest: 0.4685271\tbest: 0.4685271 (600)\ttotal: 6.63s\tremaining: 4.4s\n",
            "700:\tlearn: 0.4566636\ttest: 0.4681389\tbest: 0.4681389 (700)\ttotal: 7.72s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4545505\ttest: 0.4678054\tbest: 0.4677898 (797)\ttotal: 8.82s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4524141\ttest: 0.4676093\tbest: 0.4675839 (886)\ttotal: 9.92s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4505197\ttest: 0.4675427\tbest: 0.4675312 (980)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4675312012\n",
            "bestIteration = 980\n",
            "Shrink model to first 981 iterations.\n",
            "===== ACCURACY SCORE 0.783000 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "0:\tlearn: 0.6881326\ttest: 0.6880646\tbest: 0.6880646 (0)\ttotal: 11.7ms\tremaining: 11.7s\n",
            "100:\tlearn: 0.4990980\ttest: 0.4952576\tbest: 0.4952576 (100)\ttotal: 1.12s\tremaining: 9.95s\n",
            "200:\tlearn: 0.4751023\ttest: 0.4717907\tbest: 0.4717907 (200)\ttotal: 2.22s\tremaining: 8.81s\n",
            "300:\tlearn: 0.4683986\ttest: 0.4668133\tbest: 0.4668133 (300)\ttotal: 3.32s\tremaining: 7.7s\n",
            "400:\tlearn: 0.4647967\ttest: 0.4649794\tbest: 0.4649794 (400)\ttotal: 4.42s\tremaining: 6.61s\n",
            "500:\tlearn: 0.4620616\ttest: 0.4640359\tbest: 0.4640359 (500)\ttotal: 5.52s\tremaining: 5.5s\n",
            "600:\tlearn: 0.4596560\ttest: 0.4635137\tbest: 0.4635056 (598)\ttotal: 6.62s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4573818\ttest: 0.4631766\tbest: 0.4631738 (690)\ttotal: 7.73s\tremaining: 3.3s\n",
            "800:\tlearn: 0.4551773\ttest: 0.4628741\tbest: 0.4628717 (799)\ttotal: 8.84s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4531116\ttest: 0.4627956\tbest: 0.4627511 (869)\ttotal: 9.94s\tremaining: 1.09s\n",
            "bestTest = 0.462751123\n",
            "bestIteration = 869\n",
            "Shrink model to first 870 iterations.\n",
            "===== ACCURACY SCORE 0.786000 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "0:\tlearn: 0.6882171\ttest: 0.6881963\tbest: 0.6881963 (0)\ttotal: 11.8ms\tremaining: 11.8s\n",
            "100:\tlearn: 0.4988704\ttest: 0.4960566\tbest: 0.4960566 (100)\ttotal: 1.1s\tremaining: 9.84s\n",
            "200:\tlearn: 0.4749222\ttest: 0.4729865\tbest: 0.4729865 (200)\ttotal: 2.24s\tremaining: 8.9s\n",
            "300:\tlearn: 0.4682177\ttest: 0.4681855\tbest: 0.4681855 (300)\ttotal: 3.34s\tremaining: 7.76s\n",
            "400:\tlearn: 0.4646272\ttest: 0.4666548\tbest: 0.4666548 (400)\ttotal: 4.44s\tremaining: 6.63s\n",
            "500:\tlearn: 0.4618767\ttest: 0.4659729\tbest: 0.4659729 (500)\ttotal: 5.53s\tremaining: 5.51s\n",
            "600:\tlearn: 0.4593894\ttest: 0.4656207\tbest: 0.4656207 (600)\ttotal: 6.62s\tremaining: 4.4s\n",
            "700:\tlearn: 0.4569853\ttest: 0.4654947\tbest: 0.4654694 (659)\ttotal: 7.72s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4549114\ttest: 0.4653251\tbest: 0.4652834 (794)\ttotal: 8.8s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4528189\ttest: 0.4652873\tbest: 0.4652446 (840)\ttotal: 9.9s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4508642\ttest: 0.4652763\tbest: 0.4652399 (922)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4652399414\n",
            "bestIteration = 922\n",
            "Shrink model to first 923 iterations.\n",
            "===== ACCURACY SCORE 0.789100 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "0:\tlearn: 0.6880842\ttest: 0.6882283\tbest: 0.6882283 (0)\ttotal: 11.7ms\tremaining: 11.7s\n",
            "100:\tlearn: 0.4975299\ttest: 0.5050895\tbest: 0.5050895 (100)\ttotal: 1.1s\tremaining: 9.78s\n",
            "200:\tlearn: 0.4734323\ttest: 0.4846666\tbest: 0.4846666 (200)\ttotal: 2.2s\tremaining: 8.76s\n",
            "300:\tlearn: 0.4668901\ttest: 0.4806453\tbest: 0.4806453 (300)\ttotal: 3.29s\tremaining: 7.65s\n",
            "400:\tlearn: 0.4631661\ttest: 0.4790318\tbest: 0.4790318 (400)\ttotal: 4.39s\tremaining: 6.57s\n",
            "500:\tlearn: 0.4603991\ttest: 0.4781811\tbest: 0.4781811 (500)\ttotal: 5.5s\tremaining: 5.48s\n",
            "600:\tlearn: 0.4579519\ttest: 0.4777859\tbest: 0.4777839 (599)\ttotal: 6.61s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4556871\ttest: 0.4774457\tbest: 0.4774351 (698)\ttotal: 7.71s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4534519\ttest: 0.4771502\tbest: 0.4771384 (790)\ttotal: 8.83s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4513436\ttest: 0.4768693\tbest: 0.4768658 (898)\ttotal: 9.96s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4494042\ttest: 0.4768573\tbest: 0.4768514 (998)\ttotal: 11.1s\tremaining: 0us\n",
            "bestTest = 0.4768513672\n",
            "bestIteration = 998\n",
            "Shrink model to first 999 iterations.\n",
            "===== ACCURACY SCORE 0.776600 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "0:\tlearn: 0.6881103\ttest: 0.6881753\tbest: 0.6881753 (0)\ttotal: 12ms\tremaining: 12s\n",
            "100:\tlearn: 0.4978940\ttest: 0.5020983\tbest: 0.5020983 (100)\ttotal: 1.09s\tremaining: 9.73s\n",
            "200:\tlearn: 0.4737937\ttest: 0.4806689\tbest: 0.4806689 (200)\ttotal: 2.2s\tremaining: 8.73s\n",
            "300:\tlearn: 0.4672275\ttest: 0.4766057\tbest: 0.4766057 (300)\ttotal: 3.29s\tremaining: 7.64s\n",
            "400:\tlearn: 0.4634902\ttest: 0.4750453\tbest: 0.4750453 (400)\ttotal: 4.4s\tremaining: 6.58s\n",
            "500:\tlearn: 0.4607742\ttest: 0.4742833\tbest: 0.4742833 (500)\ttotal: 5.51s\tremaining: 5.49s\n",
            "600:\tlearn: 0.4583901\ttest: 0.4737885\tbest: 0.4737684 (586)\ttotal: 6.61s\tremaining: 4.39s\n",
            "700:\tlearn: 0.4561599\ttest: 0.4735198\tbest: 0.4735198 (700)\ttotal: 7.7s\tremaining: 3.29s\n",
            "800:\tlearn: 0.4540405\ttest: 0.4733012\tbest: 0.4733012 (800)\ttotal: 8.84s\tremaining: 2.19s\n",
            "900:\tlearn: 0.4520233\ttest: 0.4730411\tbest: 0.4730411 (900)\ttotal: 9.93s\tremaining: 1.09s\n",
            "999:\tlearn: 0.4501057\ttest: 0.4729316\tbest: 0.4728844 (954)\ttotal: 11s\tremaining: 0us\n",
            "bestTest = 0.4728844238\n",
            "bestIteration = 954\n",
            "Shrink model to first 955 iterations.\n",
            "===== ACCURACY SCORE 0.779400 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UyyFnD8s9P8"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "9_R_e7H4s9lH",
        "outputId": "c9daa81b-f480-4708-c357-ff086c7eea37"
      },
      "source": [
        "order = list(feature_importances.groupby(\"feature\").mean()\\\n",
        "             .sort_values(\"importance\", ascending=False).index)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\n",
        "plt.title(\"{} importance\".format(\"CatBoostClassifier\"))\n",
        "plt.tight_layout()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7jkH3O9tO4o"
      },
      "source": [
        "## DecisionTreeModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4rAzUtf3tQew",
        "outputId": "c1a3a8ef-acf2-475f-bd50-e931277e6c38"
      },
      "source": [
        "parameters = {\n",
        "    'max_depth': np.arange(2, 5, dtype=int),\n",
        "    'min_samples_leaf': np.arange(2, 5, dtype=int)\n",
        "}\n",
        "\n",
        "classifier = DecisionTreeClassifier(random_state=2021)\n",
        "\n",
        "model = GridSearchCV(\n",
        "    estimator = classifier,\n",
        "    param_grid = parameters,\n",
        "    scoring = 'accuracy',\n",
        "    cv = 10,\n",
        "    n_jobs = -1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = model.best_params_\n",
        "print(best_parameters)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 4, 'min_samples_leaf': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "_DoHHeoStuRZ",
        "outputId": "587220ab-902c-4493-945f-f4a94aac5379"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = DecisionTreeClassifier(\n",
        "        max_depth = best_parameters['max_depth'],\n",
        "        min_samples_leaf = best_parameters['min_samples_leaf'],\n",
        "        random_state = SEED\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    dtm_val = model.predict(X_valid)\n",
        "    dtm_val = [1 if v >= 0.5 else 0 for v in dtm_val]\n",
        "    dtm_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, dtm_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "===== ACCURACY SCORE 0.766600 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "===== ACCURACY SCORE 0.783400 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "===== ACCURACY SCORE 0.771000 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "===== ACCURACY SCORE 0.770500 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "===== ACCURACY SCORE 0.771200 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "===== ACCURACY SCORE 0.772100 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "===== ACCURACY SCORE 0.777900 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "===== ACCURACY SCORE 0.781300 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "===== ACCURACY SCORE 0.771300 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "===== ACCURACY SCORE 0.772900 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnDlaa-0wYkA"
      },
      "source": [
        "### Plot Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "pQjfAYW4wYA-",
        "outputId": "79a2201d-6650-4e1f-df37-46c2e7248506"
      },
      "source": [
        "dot_data = export_graphviz(\n",
        "    model,\n",
        "    out_file = None,\n",
        "    feature_names = X_train.columns,\n",
        "    class_names = ['0', '1'],\n",
        "    filled = True,\n",
        "    rounded = False,\n",
        "    special_characters = True,\n",
        "    precision = 3\n",
        ")\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f16b6facf90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2373pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 2373.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-548 2369,-548 2369,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#f8dfcd\" stroke=\"#000000\" points=\"1261.5,-544 1106.5,-544 1106.5,-461 1261.5,-461 1261.5,-544\"/>\n<text text-anchor=\"start\" x=\"1156\" y=\"-528.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Sex ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1151.5\" y=\"-513.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"1134.5\" y=\"-498.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 90000</text>\n<text text-anchor=\"start\" x=\"1114.5\" y=\"-483.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [51503, 38497]</text>\n<text text-anchor=\"start\" x=\"1159\" y=\"-468.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#89c5f0\" stroke=\"#000000\" points=\"984,-425 830,-425 830,-342 984,-342 984,-425\"/>\n<text text-anchor=\"start\" x=\"851.5\" y=\"-409.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"874.5\" y=\"-394.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.41</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39527</text>\n<text text-anchor=\"start\" x=\"838\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [11394, 28133]</text>\n<text text-anchor=\"start\" x=\"882\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1106.4717,-469.1936C1071.3573,-454.1084 1029.71,-436.2166 993.5761,-420.6934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"994.5994,-417.3237 984.0298,-416.5922 991.8363,-423.7553 994.5994,-417.3237\"/>\n<text text-anchor=\"middle\" x=\"993.2944\" y=\"-436.1122\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#eca26c\" stroke=\"#000000\" points=\"1548.5,-425 1393.5,-425 1393.5,-342 1548.5,-342 1548.5,-425\"/>\n<text text-anchor=\"start\" x=\"1416.5\" y=\"-409.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1434.5\" y=\"-394.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.326</text>\n<text text-anchor=\"start\" x=\"1421.5\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50473</text>\n<text text-anchor=\"start\" x=\"1401.5\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [40109, 10364]</text>\n<text text-anchor=\"start\" x=\"1446\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>0&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1261.6663,-470.2969C1299.3139,-454.6869 1344.6798,-435.8767 1383.5405,-419.7637\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1385.3747,-422.7922 1393.2716,-415.7289 1382.6936,-416.326 1385.3747,-422.7922\"/>\n<text text-anchor=\"middle\" x=\"1383.7128\" y=\"-435.1293\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#abd5f4\" stroke=\"#000000\" points=\"528.5,-306 381.5,-306 381.5,-223 528.5,-223 528.5,-306\"/>\n<text text-anchor=\"start\" x=\"413\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"418.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.464</text>\n<text text-anchor=\"start\" x=\"406\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25311</text>\n<text text-anchor=\"start\" x=\"389.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9240, 16071]</text>\n<text text-anchor=\"start\" x=\"430\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M829.812,-363.1784C748.8041,-341.8511 621.877,-308.4344 538.5563,-286.4982\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"539.4316,-283.1095 528.87,-283.9481 537.6494,-289.8788 539.4316,-283.1095\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#5cafea\" stroke=\"#000000\" points=\"980.5,-306 833.5,-306 833.5,-223 980.5,-223 980.5,-306\"/>\n<text text-anchor=\"start\" x=\"864\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"870.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14216</text>\n<text text-anchor=\"start\" x=\"841.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2154, 12062]</text>\n<text text-anchor=\"start\" x=\"882\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M907,-341.8796C907,-333.6838 907,-324.9891 907,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"910.5001,-316.298 907,-306.2981 903.5001,-316.2981 910.5001,-316.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#8fc8f0\" stroke=\"#000000\" points=\"300,-187 154,-187 154,-104 300,-104 300,-187\"/>\n<text text-anchor=\"start\" x=\"184\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"190.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.422</text>\n<text text-anchor=\"start\" x=\"177.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16481</text>\n<text text-anchor=\"start\" x=\"162\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4987, 11494]</text>\n<text text-anchor=\"start\" x=\"202\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M381.2898,-226.0284C358.2166,-213.9859 332.6164,-200.6243 309.0079,-188.3024\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"310.5513,-185.1599 300.0667,-183.6357 307.3124,-191.3655 310.5513,-185.1599\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#f1f8fd\" stroke=\"#000000\" points=\"525,-187 385,-187 385,-104 525,-104 525,-187\"/>\n<text text-anchor=\"start\" x=\"420\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Ticket ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"418.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"409.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8830</text>\n<text text-anchor=\"start\" x=\"393\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4253, 4577]</text>\n<text text-anchor=\"start\" x=\"430\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M455,-222.8796C455,-214.6838 455,-205.9891 455,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"458.5001,-197.298 455,-187.2981 451.5001,-197.2981 458.5001,-197.298\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#84c2ef\" stroke=\"#000000\" points=\"146,-68 0,-68 0,0 146,0 146,-68\"/>\n<text text-anchor=\"start\" x=\"36.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.399</text>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15216</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4185, 11031]</text>\n<text text-anchor=\"start\" x=\"48\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.6561,-103.9815C156.2006,-94.2394 141.8869,-83.8759 128.5133,-74.193\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.4763,-71.2933 120.3238,-68.2637 126.3711,-76.9632 130.4763,-71.2933\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#f4caab\" stroke=\"#000000\" points=\"289.5,-68 164.5,-68 164.5,0 289.5,0 289.5,-68\"/>\n<text text-anchor=\"start\" x=\"190.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.464</text>\n<text text-anchor=\"start\" x=\"181.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1265</text>\n<text text-anchor=\"start\" x=\"172.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [802, 463]</text>\n<text text-anchor=\"start\" x=\"202\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-103.9815C227,-95.618 227,-86.7965 227,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-78.2636 227,-68.2637 223.5001,-78.2637 230.5001,-78.2636\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#eeab7b\" stroke=\"#000000\" points=\"432.5,-68 307.5,-68 307.5,0 432.5,0 432.5,-68\"/>\n<text text-anchor=\"start\" x=\"333.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"328\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 555</text>\n<text text-anchor=\"start\" x=\"315.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [416, 139]</text>\n<text text-anchor=\"start\" x=\"345\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M423.3491,-103.9815C416.4829,-94.9747 409.2118,-85.4367 402.3202,-76.3965\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.9664,-74.0945 396.1203,-68.2637 399.3995,-78.3383 404.9664,-74.0945\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e4f2fb\" stroke=\"#000000\" points=\"591,-68 451,-68 451,0 591,0 591,-68\"/>\n<text text-anchor=\"start\" x=\"484.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.497</text>\n<text text-anchor=\"start\" x=\"475.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8275</text>\n<text text-anchor=\"start\" x=\"459\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3837, 4438]</text>\n<text text-anchor=\"start\" x=\"496\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M479.576,-103.9815C484.7986,-95.1585 490.3229,-85.8258 495.5763,-76.9506\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"498.6364,-78.652 500.7184,-68.2637 492.6126,-75.0863 498.6364,-78.652\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#58ade9\" stroke=\"#000000\" points=\"903,-187 757,-187 757,-104 903,-104 903,-187\"/>\n<text text-anchor=\"start\" x=\"788\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"793.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.236</text>\n<text text-anchor=\"start\" x=\"780.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13663</text>\n<text text-anchor=\"start\" x=\"765\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1872, 11791]</text>\n<text text-anchor=\"start\" x=\"805\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M880.0691,-222.8796C874.4163,-214.1434 868.3967,-204.8404 862.5634,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"865.4169,-193.7924 857.0458,-187.2981 859.5399,-197.5952 865.4169,-193.7924\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#fefaf7\" stroke=\"#000000\" points=\"1046.5,-187 921.5,-187 921.5,-104 1046.5,-104 1046.5,-187\"/>\n<text text-anchor=\"start\" x=\"935\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Name ≤ 25810.0</text>\n<text text-anchor=\"start\" x=\"955\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"942\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 553</text>\n<text text-anchor=\"start\" x=\"929.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [282, 271]</text>\n<text text-anchor=\"start\" x=\"959\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M933.9309,-222.8796C939.5837,-214.1434 945.6033,-204.8404 951.4366,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"954.4601,-197.5952 956.9542,-187.2981 948.5831,-193.7924 954.4601,-197.5952\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#52aae8\" stroke=\"#000000\" points=\"749,-68 609,-68 609,0 749,0 749,-68\"/>\n<text text-anchor=\"start\" x=\"642.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.201</text>\n<text text-anchor=\"start\" x=\"630\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 11235</text>\n<text text-anchor=\"start\" x=\"617\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1271, 9964]</text>\n<text text-anchor=\"start\" x=\"654\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M773.7732,-103.9815C760.7043,-94.3313 746.8097,-84.0714 733.8032,-74.4673\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.5255,-71.3883 725.4019,-68.2637 731.3674,-77.0195 735.5255,-71.3883\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#7abdee\" stroke=\"#000000\" points=\"899,-68 767,-68 767,0 899,0 899,-68\"/>\n<text text-anchor=\"start\" x=\"796.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.373</text>\n<text text-anchor=\"start\" x=\"787.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2428</text>\n<text text-anchor=\"start\" x=\"775\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [601, 1827]</text>\n<text text-anchor=\"start\" x=\"808\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M831.1171,-103.9815C831.3421,-95.618 831.5795,-86.7965 831.807,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"835.3078,-78.3542 832.0781,-68.2637 828.3103,-78.1659 835.3078,-78.3542\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#fdf5ef\" stroke=\"#000000\" points=\"1042.5,-68 917.5,-68 917.5,0 1042.5,0 1042.5,-68\"/>\n<text text-anchor=\"start\" x=\"943.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"938\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 538</text>\n<text text-anchor=\"start\" x=\"925.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [280, 258]</text>\n<text text-anchor=\"start\" x=\"955\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M982.5105,-103.9815C982.2105,-95.618 981.894,-86.7965 981.5907,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"985.0855,-78.1317 981.2292,-68.2637 978.09,-78.3828 985.0855,-78.1317\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#57ace9\" stroke=\"#000000\" points=\"1163,-68 1061,-68 1061,0 1163,0 1163,-68\"/>\n<text text-anchor=\"start\" x=\"1075.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.231</text>\n<text text-anchor=\"start\" x=\"1074\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1069\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 13]</text>\n<text text-anchor=\"start\" x=\"1087\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1031.6625,-103.9815C1042.5297,-94.5151 1054.0705,-84.462 1064.9135,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1067.4245,-77.4712 1072.6659,-68.2637 1062.8266,-72.1929 1067.4245,-77.4712\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#fdf5ef\" stroke=\"#000000\" points=\"1541,-306 1401,-306 1401,-223 1541,-223 1541,-306\"/>\n<text text-anchor=\"start\" x=\"1429\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"1434.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"1425.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7251</text>\n<text text-anchor=\"start\" x=\"1409\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3778, 3473]</text>\n<text text-anchor=\"start\" x=\"1446\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1471,-341.8796C1471,-333.6838 1471,-324.9891 1471,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1474.5001,-316.298 1471,-306.2981 1467.5001,-316.2981 1474.5001,-316.298\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"#ea995f\" stroke=\"#000000\" points=\"1975.5,-306 1828.5,-306 1828.5,-223 1975.5,-223 1975.5,-306\"/>\n<text text-anchor=\"start\" x=\"1860\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"1865.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.268</text>\n<text text-anchor=\"start\" x=\"1852.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 43222</text>\n<text text-anchor=\"start\" x=\"1836.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [36331, 6891]</text>\n<text text-anchor=\"start\" x=\"1877\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 16&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>16&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1548.5519,-362.0877C1624.6689,-341.0717 1740.3974,-309.1188 1818.5,-287.5545\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1819.601,-290.8816 1828.3088,-284.8463 1817.738,-284.134 1819.601,-290.8816\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#dfeffb\" stroke=\"#000000\" points=\"1464,-187 1324,-187 1324,-104 1464,-104 1464,-187\"/>\n<text text-anchor=\"start\" x=\"1351\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1357.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.496</text>\n<text text-anchor=\"start\" x=\"1348.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5550</text>\n<text text-anchor=\"start\" x=\"1332\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2529, 3021]</text>\n<text text-anchor=\"start\" x=\"1369\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1444.0691,-222.8796C1438.4163,-214.1434 1432.3967,-204.8404 1426.5634,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.4169,-193.7924 1421.0458,-187.2981 1423.5399,-197.5952 1429.4169,-193.7924\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#eeaf81\" stroke=\"#000000\" points=\"1614,-187 1482,-187 1482,-104 1614,-104 1614,-187\"/>\n<text text-anchor=\"start\" x=\"1492.5\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1515.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.39</text>\n<text text-anchor=\"start\" x=\"1502.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1701</text>\n<text text-anchor=\"start\" x=\"1490\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1249, 452]</text>\n<text text-anchor=\"start\" x=\"1523\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 17&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>17&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1497.9309,-222.8796C1503.5837,-214.1434 1509.6033,-204.8404 1515.4366,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1518.4601,-197.5952 1520.9542,-187.2981 1512.5831,-193.7924 1518.4601,-197.5952\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"#c6e3f7\" stroke=\"#000000\" points=\"1321,-68 1181,-68 1181,0 1321,0 1321,-68\"/>\n<text text-anchor=\"start\" x=\"1214.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.486</text>\n<text text-anchor=\"start\" x=\"1205.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4754</text>\n<text text-anchor=\"start\" x=\"1189\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1976, 2778]</text>\n<text text-anchor=\"start\" x=\"1226\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1340.7521,-103.9815C1328.3756,-94.3313 1315.2172,-84.0714 1302.8997,-74.4673\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1304.9818,-71.6525 1294.9435,-68.2637 1300.6775,-77.1728 1304.9818,-71.6525\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#f0b890\" stroke=\"#000000\" points=\"1464.5,-68 1339.5,-68 1339.5,0 1464.5,0 1464.5,-68\"/>\n<text text-anchor=\"start\" x=\"1365.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.424</text>\n<text text-anchor=\"start\" x=\"1360\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 796</text>\n<text text-anchor=\"start\" x=\"1347.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [553, 243]</text>\n<text text-anchor=\"start\" x=\"1377\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1396.9789,-103.9815C1397.579,-95.618 1398.2119,-86.7965 1398.8186,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1402.3169,-78.4885 1399.5416,-68.2637 1395.3349,-77.9875 1402.3169,-78.4885\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#e99457\" stroke=\"#000000\" points=\"1599.5,-68 1482.5,-68 1482.5,0 1599.5,0 1599.5,-68\"/>\n<text text-anchor=\"start\" x=\"1504.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.227</text>\n<text text-anchor=\"start\" x=\"1499\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 405</text>\n<text text-anchor=\"start\" x=\"1490.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [352, 53]</text>\n<text text-anchor=\"start\" x=\"1516\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1545.3935,-103.9815C1544.8684,-95.618 1544.3146,-86.7965 1543.7837,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1547.2709,-78.0247 1543.1511,-68.2637 1540.2846,-78.4634 1547.2709,-78.0247\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"#f1b991\" stroke=\"#000000\" points=\"1742.5,-68 1617.5,-68 1617.5,0 1742.5,0 1742.5,-68\"/>\n<text text-anchor=\"start\" x=\"1643.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.426</text>\n<text text-anchor=\"start\" x=\"1634.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1296</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [897, 399]</text>\n<text text-anchor=\"start\" x=\"1655\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1597.1519,-103.9815C1608.4676,-94.4232 1620.4913,-84.2668 1631.7675,-74.7419\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1634.0559,-77.3904 1639.4367,-68.2637 1629.5388,-72.0429 1634.0559,-77.3904\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"#eda978\" stroke=\"#000000\" points=\"1975.5,-187 1828.5,-187 1828.5,-104 1975.5,-104 1975.5,-187\"/>\n<text text-anchor=\"start\" x=\"1862.5\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fare ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"1865.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.365</text>\n<text text-anchor=\"start\" x=\"1852.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19316</text>\n<text text-anchor=\"start\" x=\"1836.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [14678, 4638]</text>\n<text text-anchor=\"start\" x=\"1877\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1902,-222.8796C1902,-214.6838 1902,-205.9891 1902,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1905.5001,-197.298 1902,-187.2981 1898.5001,-197.2981 1905.5001,-197.298\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<polygon fill=\"#e88e4e\" stroke=\"#000000\" points=\"2215.5,-187 2068.5,-187 2068.5,-104 2215.5,-104 2215.5,-187\"/>\n<text text-anchor=\"start\" x=\"2101\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Parch ≤ 0.028</text>\n<text text-anchor=\"start\" x=\"2105.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.171</text>\n<text text-anchor=\"start\" x=\"2092.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 23906</text>\n<text text-anchor=\"start\" x=\"2076.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [21653, 2253]</text>\n<text text-anchor=\"start\" x=\"2117\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 24&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>24&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1975.6389,-227.9874C2002.0076,-214.9129 2031.9056,-200.0885 2059.0108,-186.6488\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2060.6825,-189.7266 2068.0868,-182.1486 2057.5729,-183.4552 2060.6825,-189.7266\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"#ea985c\" stroke=\"#000000\" points=\"1893,-68 1761,-68 1761,0 1893,0 1893,-68\"/>\n<text text-anchor=\"start\" x=\"1790.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"1781.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6465</text>\n<text text-anchor=\"start\" x=\"1769\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5484, 981]</text>\n<text text-anchor=\"start\" x=\"1802\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1874.0728,-103.9815C1868.0762,-95.0666 1861.7296,-85.6313 1855.7041,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1858.5328,-74.6078 1850.0473,-68.2637 1852.7245,-78.5147 1858.5328,-74.6078\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<polygon fill=\"#efb388\" stroke=\"#000000\" points=\"2051,-68 1911,-68 1911,0 2051,0 2051,-68\"/>\n<text text-anchor=\"start\" x=\"1944.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.407</text>\n<text text-anchor=\"start\" x=\"1931.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12851</text>\n<text text-anchor=\"start\" x=\"1919\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9194, 3657]</text>\n<text text-anchor=\"start\" x=\"1956\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 25&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>25&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1931.4167,-103.9815C1937.7331,-95.0666 1944.4182,-85.6313 1950.7651,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1953.7981,-78.4466 1956.7235,-68.2637 1948.0864,-74.3998 1953.7981,-78.4466\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<polygon fill=\"#e78c4b\" stroke=\"#000000\" points=\"2215,-68 2069,-68 2069,0 2215,0 2215,-68\"/>\n<text text-anchor=\"start\" x=\"2105.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.152</text>\n<text text-anchor=\"start\" x=\"2092.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19972</text>\n<text text-anchor=\"start\" x=\"2077\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [18311, 1661]</text>\n<text text-anchor=\"start\" x=\"2117\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2142,-103.9815C2142,-95.618 2142,-86.7965 2142,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2145.5001,-78.2636 2142,-68.2637 2138.5001,-78.2637 2145.5001,-78.2636\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<polygon fill=\"#ea975c\" stroke=\"#000000\" points=\"2365,-68 2233,-68 2233,0 2365,0 2365,-68\"/>\n<text text-anchor=\"start\" x=\"2262.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.256</text>\n<text text-anchor=\"start\" x=\"2253.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3934</text>\n<text text-anchor=\"start\" x=\"2241\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3342, 592]</text>\n<text text-anchor=\"start\" x=\"2274\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>28&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2200.461,-103.9815C2214.2508,-94.1881 2228.9247,-83.7668 2242.6205,-74.0402\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2244.8785,-76.7295 2251.005,-68.0856 2240.8253,-71.0223 2244.8785,-76.7295\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXEQ8Acwwp39"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "o1oteBFmwqKS",
        "outputId": "54ae8ee6-53e1-43c9-9e4d-4f0784c4a82a"
      },
      "source": [
        "submission_df['submit_lgb'] = [1 if pred >= 0.5 else 0 for pred in lgb_preds]\n",
        "submission_df['submit_ctb'] = [1 if pred >= 0.5 else 0 for pred in ctb_preds]\n",
        "submission_df['submit_dtm'] = [1 if pred >= 0.5 else 0 for pred in dtm_preds]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jywozOfj1RTh",
        "outputId": "417680f5-7c15-49c2-9e7b-03b671e2f36a"
      },
      "source": [
        "submission_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>submit_lgb</th>\n",
              "      <th>submit_ctb</th>\n",
              "      <th>submit_dtm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100003</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100004</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>199995</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>199996</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>199997</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>199998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>199999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId  Survived  submit_lgb  submit_ctb  submit_dtm\n",
              "0           100000         1           0           0           0\n",
              "1           100001         1           1           1           1\n",
              "2           100002         1           1           1           1\n",
              "3           100003         1           0           0           0\n",
              "4           100004         1           1           1           1\n",
              "...            ...       ...         ...         ...         ...\n",
              "99995       199995         1           1           1           1\n",
              "99996       199996         1           0           0           0\n",
              "99997       199997         1           0           0           0\n",
              "99998       199998         1           1           1           1\n",
              "99999       199999         1           1           1           1\n",
              "\n",
              "[100000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VsOsxxeixDaJ",
        "outputId": "e239b60d-6891-4e97-a128-7686a1d1a2d2"
      },
      "source": [
        "# 세 모델의 행 별로 생존자의 수를 더함\n",
        "# 0은 모두 사망으로 예측, 1은 하나만, 2는 두 모델, 3은 세 모델이 모두 생존으로 예측\n",
        "submission_df[[col for col in submission_df.columns if col.startswith('submit_')]]\\\n",
        ".sum(axis=1).value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    63518\n",
              "3    29313\n",
              "1     4793\n",
              "2     2376\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xNSHXgZFypsn",
        "outputId": "b6605a63-d294-465e-c347-208d92dfdc43"
      },
      "source": [
        "# 합이 2보다 크면 True -> int로 변환 (1)\n",
        "submission_df[TARGET] = (submission_df[[col for col in submission_df.columns\\\n",
        "                                  if col.startswith('submit_')]].sum(axis=1) >= 2)\\\n",
        "                                  .astype(int)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nIORpSBv2wk1",
        "outputId": "60bc9d99-4a6f-44e2-b01a-8133b5c67ce5"
      },
      "source": [
        "submission_df.drop([col for col in submission_df.columns if col.startswith('submit_')],\\\n",
        "                 axis=1, inplace=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zv_RFdiA1EA4",
        "outputId": "dc9f2b84-6e41-427c-8a29-480eb9432260"
      },
      "source": [
        "submission_df.to_csv('Apr_Ensemble.csv', index=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVJC36CKuvXk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bva8jI6q4la9"
      },
      "source": [
        "score: 0.80305, 369등"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G61OWeSWwgQF"
      },
      "source": [
        "## Pytorch Deeplearning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4mVre2uik7zt",
        "outputId": "c7926e03-d08f-4658-c6cf-f2ff43232d0c"
      },
      "source": [
        "# 데이터 다시 로드\n",
        "train_df = pd.read_csv(PATH+'train.csv')\n",
        "test_df = pd.read_csv(PATH+'test.csv')\n",
        "submission_df = pd.read_csv(PATH+'sample_submission.csv')\n",
        "\n",
        "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OgOpC4UywgKH",
        "outputId": "d1e8355c-aa5f-40ff-e469-f569427732e9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "XehJvHLNty2x",
        "outputId": "5afa26b7-eca6-406c-f3e0-8cb937150520"
      },
      "source": [
        "# Preprocessing Again\n",
        "y = train_df['Survived']\n",
        "# 필요없거나 원핫인코딩으로 들어가는 피쳐는 단순하게 제거했음\n",
        "X = fill_nan_values(all_df).drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
        "\n",
        "print(X.isnull().sum())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pclass      0\n",
            "Sex         0\n",
            "Age         0\n",
            "SibSp       0\n",
            "Parch       0\n",
            "Fare        0\n",
            "Embarked    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "X15b_etYtyyb",
        "outputId": "656b8fff-f4ff-4fdb-8623-66c47458ea88"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>34.464565</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3.337192</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.464565</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.663750</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4.280686</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.641910</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.170196</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass   Sex        Age  SibSp  Parch      Fare Embarked\n",
              "0       1  male  34.464565      2      0  3.337192        S\n",
              "1       3  male  34.464565      0      0  2.663750        S\n",
              "2       3  male   0.330000      1      2  4.280686        S\n",
              "3       3  male  19.000000      0      0  2.641910        S\n",
              "4       3  male  25.000000      0      0  2.170196        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "RL7vCD2i6ect",
        "outputId": "cdd74e2f-b72f-49fc-b23a-563dddae28dd"
      },
      "source": [
        "def label_encoder(c):\n",
        "    le = LabelEncoder()\n",
        "    return le.fit_transform(c)\n",
        "scaler = StandardScaler()\n",
        "# Age와 Fare에는 표준화를 적용\n",
        "# Sex, Embarked, SibSp, Parch에는 라벨 인코딩\n",
        "le = X[['Sex', 'Embarked', 'SibSp', 'Parch']].apply(label_encoder)\n",
        "sc = pd.DataFrame(scaler.fit_transform(X[['Age', 'Fare']]), columns = ['Age', 'Fare'])\n",
        "\n",
        "X2 = pd.concat([le, sc], axis=1)\n",
        "X2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-8.614253e-16</td>\n",
              "      <td>0.134351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-8.614253e-16</td>\n",
              "      <td>-0.533837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.069149e+00</td>\n",
              "      <td>1.070483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-9.374220e-01</td>\n",
              "      <td>-0.555506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.737175e-01</td>\n",
              "      <td>-1.023540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-4.524827e-01</td>\n",
              "      <td>-0.786852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.487275e+00</td>\n",
              "      <td>1.028715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.598657e-01</td>\n",
              "      <td>-0.722092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8.811005e-01</td>\n",
              "      <td>0.220096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.961612e-01</td>\n",
              "      <td>2.062203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sex  Embarked  SibSp  Parch           Age      Fare\n",
              "0         1         2      2      0 -8.614253e-16  0.134351\n",
              "1         1         2      0      0 -8.614253e-16 -0.533837\n",
              "2         1         2      1      2 -2.069149e+00  1.070483\n",
              "3         1         2      0      0 -9.374220e-01 -0.555506\n",
              "4         1         2      0      0 -5.737175e-01 -1.023540\n",
              "...     ...       ...    ...    ...           ...       ...\n",
              "199995    0         1      0      0 -4.524827e-01 -0.786852\n",
              "199996    1         2      1      0  1.487275e+00  1.028715\n",
              "199997    1         2      0      0  7.598657e-01 -0.722092\n",
              "199998    0         0      1      2  8.811005e-01  0.220096\n",
              "199999    0         0      0      2  3.961612e-01  2.062203\n",
              "\n",
              "[200000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QX3Qjpc_lTgY",
        "outputId": "4debdd79-c09d-480a-e4cc-e5c53a19863a"
      },
      "source": [
        "# 피쳐 엔지니어링 후 다시 train/ test 분리\n",
        "train_df2 = X2[:train_df.shape[0]]\n",
        "test_df2 = X2[train_df.shape[0]:]\n",
        "print(train_df2.shape, test_df2.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(100000, 6) (100000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wLYzqXEA7bY8",
        "outputId": "4a50bb82-ab72-4508-f69d-a3d352bbeabc"
      },
      "source": [
        "# train / valid 데이터 7:3 비율로 분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_df2, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Y6uSIsGf-Dcq",
        "outputId": "f0eff98c-4833-4bdb-ac0b-edc5c0b5153c"
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XDrQ9eGu-RZy",
        "outputId": "5f29b55f-4efc-403d-a2cd-8d7b9ad25c55"
      },
      "source": [
        "## train / valid data\n",
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "train_data = trainData(torch.tensor(X_train.to_numpy()), \n",
        "                       torch.tensor(y_train.to_numpy()))\n",
        "\n",
        "valid_data = trainData(torch.tensor(X_valid.to_numpy()), \n",
        "                       torch.tensor(y_valid.to_numpy()))\n",
        "# test data\n",
        "class TestData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "test_data = TestData(torch.tensor(test_df2.to_numpy()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "U87ic73W-hhz",
        "outputId": "18789ce1-253e-49f4-bb46-6dd69739075b"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_data, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GLYxGnfO_Hfj",
        "outputId": "c16fdb19-04d5-4900-b8d7-5821ced44efc"
      },
      "source": [
        "class binaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(binaryClassification, self).__init__()\n",
        "        # Number of input features is 6\n",
        "        self.layer_1 = nn.Linear(6, 64) \n",
        "        self.layer_2 = nn.Linear(64, 64)\n",
        "        self.layer_out = nn.Linear(64, 1) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8H57MShK_cmZ",
        "outputId": "91ea39ef-1d28-4714-d761-d89fa580d6ea"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "mhF1VvMp_eGs",
        "outputId": "85a9493d-33ed-4973-e9f3-817fb6400852"
      },
      "source": [
        "model = binaryClassification()\n",
        "model.to(device)\n",
        "print(model)\n",
        "# 이진 분류 할떄 쓰는 loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "binaryClassification(\n",
            "  (layer_1): Linear(in_features=6, out_features=64, bias=True)\n",
            "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HRL_WuZj_pNw",
        "outputId": "eb0a34ff-6c97-48c0-95ae-ad1609a63558"
      },
      "source": [
        "# train epoch 설정\n",
        "epochs = EPOCHS\n",
        "\n",
        "# loss 추적\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "tn_loss = []\n",
        "for epoch in range(1,epochs+1):\n",
        "\n",
        "    # train/ validation loss 초기화\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # 모델 훈련\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):       \n",
        "        \n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # optimizer 초기화\n",
        "        optimizer.zero_grad()\n",
        "        # 계산\n",
        "        output = model(data.float())\n",
        "        # loss 계산\n",
        "        loss = criterion(output, target.unsqueeze(1).type_as(output))\n",
        "        # 그래디언트 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        \n",
        "        # train loss 업데이트\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # 모델 검증\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            \n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # 계산\n",
        "            output = model(data.float())\n",
        "            # loss 계산\n",
        "            loss = criterion(output, target.unsqueeze(1).type_as(output))\n",
        "            # validation loss 업데이트\n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # 평균 loss 계산\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    val_loss.append(valid_loss)\n",
        "    tn_loss.append(train_loss)\n",
        "    # loss statistics 출력\n",
        "    print('Epoch: {} \\t Training Loss: {:.3f} \\t Validation Loss: {:.3f}'.format(epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # validation loss 감소할 경우 모델 저장\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(\"Validation loss decreased {:.4f}--->{:.4f}  Saving model...\".format(valid_loss_min, valid_loss))\n",
        "        # 현재 모델 저장\n",
        "        torch.save(model.state_dict(), 'model_state.pt')\n",
        "        valid_loss_min = valid_loss\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Training Loss: 0.504 \t Validation Loss: 0.498\n",
            "Validation loss decreased inf--->0.4982  Saving model...\n",
            "Epoch: 2 \t Training Loss: 0.503 \t Validation Loss: 0.499\n",
            "Epoch: 3 \t Training Loss: 0.503 \t Validation Loss: 0.497\n",
            "Validation loss decreased 0.4982--->0.4969  Saving model...\n",
            "Epoch: 4 \t Training Loss: 0.503 \t Validation Loss: 0.495\n",
            "Validation loss decreased 0.4969--->0.4955  Saving model...\n",
            "Epoch: 5 \t Training Loss: 0.502 \t Validation Loss: 0.496\n",
            "Epoch: 6 \t Training Loss: 0.502 \t Validation Loss: 0.498\n",
            "Epoch: 7 \t Training Loss: 0.501 \t Validation Loss: 0.496\n",
            "Epoch: 8 \t Training Loss: 0.502 \t Validation Loss: 0.496\n",
            "Epoch: 9 \t Training Loss: 0.501 \t Validation Loss: 0.496\n",
            "Epoch: 10 \t Training Loss: 0.502 \t Validation Loss: 0.496\n",
            "Epoch: 11 \t Training Loss: 0.501 \t Validation Loss: 0.496\n",
            "Epoch: 12 \t Training Loss: 0.501 \t Validation Loss: 0.498\n",
            "Epoch: 13 \t Training Loss: 0.501 \t Validation Loss: 0.497\n",
            "Epoch: 14 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 15 \t Training Loss: 0.500 \t Validation Loss: 0.497\n",
            "Epoch: 16 \t Training Loss: 0.501 \t Validation Loss: 0.496\n",
            "Epoch: 17 \t Training Loss: 0.501 \t Validation Loss: 0.495\n",
            "Validation loss decreased 0.4955--->0.4952  Saving model...\n",
            "Epoch: 18 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 19 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 20 \t Training Loss: 0.500 \t Validation Loss: 0.497\n",
            "Epoch: 21 \t Training Loss: 0.499 \t Validation Loss: 0.497\n",
            "Epoch: 22 \t Training Loss: 0.499 \t Validation Loss: 0.498\n",
            "Epoch: 23 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 24 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 25 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 26 \t Training Loss: 0.500 \t Validation Loss: 0.497\n",
            "Epoch: 27 \t Training Loss: 0.500 \t Validation Loss: 0.496\n",
            "Epoch: 28 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 29 \t Training Loss: 0.499 \t Validation Loss: 0.495\n",
            "Validation loss decreased 0.4952--->0.4949  Saving model...\n",
            "Epoch: 30 \t Training Loss: 0.499 \t Validation Loss: 0.497\n",
            "Epoch: 31 \t Training Loss: 0.499 \t Validation Loss: 0.495\n",
            "Epoch: 32 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 33 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 34 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 35 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 36 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 37 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 38 \t Training Loss: 0.500 \t Validation Loss: 0.497\n",
            "Epoch: 39 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 40 \t Training Loss: 0.499 \t Validation Loss: 0.495\n",
            "Validation loss decreased 0.4949--->0.4946  Saving model...\n",
            "Epoch: 41 \t Training Loss: 0.499 \t Validation Loss: 0.495\n",
            "Epoch: 42 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 43 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 44 \t Training Loss: 0.498 \t Validation Loss: 0.495\n",
            "Epoch: 45 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 46 \t Training Loss: 0.499 \t Validation Loss: 0.496\n",
            "Epoch: 47 \t Training Loss: 0.498 \t Validation Loss: 0.495\n",
            "Epoch: 48 \t Training Loss: 0.498 \t Validation Loss: 0.495\n",
            "Epoch: 49 \t Training Loss: 0.498 \t Validation Loss: 0.495\n",
            "Epoch: 50 \t Training Loss: 0.498 \t Validation Loss: 0.495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "mJKtN8L7nbrj",
        "outputId": "a8736ccb-feb7-4b7e-f98f-0166c0fa6589"
      },
      "source": [
        "# 학습한 모델 load\n",
        "model.load_state_dict(torch.load('model_state.pt'))\n",
        "model.eval()\n",
        "model.cuda()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "binaryClassification(\n",
              "  (layer_1): Linear(in_features=6, out_features=64, bias=True)\n",
              "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "skuMUmDrIIhW",
        "outputId": "faa25f15-d1cd-4a0d-8bdc-ecab3e51be2e"
      },
      "source": [
        "# 모델 test \n",
        "y_pred_list = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = model(X_batch.float())\n",
        "        y_test_pred = torch.sigmoid(y_test_pred)\n",
        "        y_pred_tag = torch.round(y_test_pred)\n",
        "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
        "y_pred_list = map(int, y_pred_list)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TAPEYGVJLGXg",
        "outputId": "855b6121-73db-41bf-a558-94c54a53be38"
      },
      "source": [
        "# 제출\n",
        "id = submission_df['PassengerId']\n",
        "sub = pd.concat([id, pd.Series(y_pred_list)], axis=1)\n",
        "sub.columns = ['PassengerId', 'Survived']"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "t5DqLVtaLTHe",
        "outputId": "420a05d1-7790-484f-bdaf-c73f7657ff97"
      },
      "source": [
        "sub"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>199995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>199996</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>199997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>199998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>199999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId  Survived\n",
              "0           100000         0\n",
              "1           100001         1\n",
              "2           100002         1\n",
              "3           100003         0\n",
              "4           100004         1\n",
              "...            ...       ...\n",
              "99995       199995         1\n",
              "99996       199996         0\n",
              "99997       199997         0\n",
              "99998       199998         1\n",
              "99999       199999         1\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0VwRCR6Lhsg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "429cc8e0-ce16-4ccf-be25-e4aa2474e810"
      },
      "source": [
        "sub.to_csv('torch_submission.csv', index=False)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjMuQ76gumhi"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/68543150/119361148-4caf7800-bce6-11eb-9e1d-0c622cd6d12c.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3DPLIR3vX26"
      },
      "source": [
        "- 때로는 간단한게 최고"
      ]
    }
  ]
}